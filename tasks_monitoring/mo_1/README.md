## 1. 
- **CPU usage** — вычисления → нужно понимать нагрузку.
- **RAM usage** — может утекать, важно отслеживать.
- **Disk space + inodes** — сохраняются отчёты, следим за местом и количеством файлов.
- **Disk I/O** — может стать узким местом.
- **HTTP response codes** — 2xx/4xx/5xx для оценки доступности.
**Обоснование**: Метрики покрывают CPU, хранение, производительность и доступность HTTP.

## 2.
Менеджеру важно понимать: сервис работает или нет, а не глубину inodes.

- Выносим **отдельный дашборд для бизнеса**:
  - % успешных запросов (SLA)
  - Среднее время ответа
  - Сколько задач завершились успешно
  - Кол-во ошибок — в понятных терминах
- Можно использовать:
  - **Grafana + простой дашборд**
  - **Metabase / Redash** — визуализация бизнес-метрик
  - **StatusPage** — автоматический отчёт о работоспособности
- Пишем человеческим языком:
  > "За сутки — 97% успешных отчётов, время отклика 320мс, ошибок: 5 внутренних"

## 3.
### Вариант 1 — просто и бесплатно
- Приложение пишет ошибки в консоль (в терминал).
- Эти сообщения можно смотреть через встроенный инструмент на сервере (`journalctl`).
- Можно настроить простой скрипт, который раз в пару минут читает эти сообщения и ищет там слово “ERROR”.
- Если нашёл — отправляет уведомление, например, в Telegram или на почту.
### Вариант 2 — чуть умнее, но всё ещё бесплатно
- Пишем на Python небольшой скрипт:
  - Он читает ошибки из логов.
  - Сохраняет список новых ошибок.
  - Показывает, когда и что пошло не так.
  - Может даже отправить отчёт в чат.
### Вариант 3 — использовать бесплатные инструменты
- Есть бесплатные варианты лог-систем (например, Loki, или просто лог-файлы с веб-интерфейсом).
- Можно подключить это позже, когда будет чуть больше времени или ресурсов.

## 4.
Предполагаю, что в расчёт попадают не только успешные HTTP-ответы, но и запросы, которые вообще не получили ответ — например, таймауты или обрывы соединения.
Такие случаи не имеют кода ответа, но учитываются в "всего запросов", из-за чего доля 2xx падает.
Правильнее считать SLA как долю 2xx среди всех **реальных HTTP-ответов**, а ошибки соединения учитывать отдельно.

## 5.
### Pull-системы (мониторинг сам забирает данные)
**Плюсы**:
- Ты полностью контролируешь, что и когда собирать — никаких лишних данных.
- Легче масштабировать: сервер сам решает, как часто опрашивать.
**Минусы**:
- Если используется NAT или кривой firewall могут быть проблемы с доступом.
- Временные задачи (например, батчи) сложнее отслеживать, можно упустить данные.

### Push-системы (серверы сами присылают данные)
**Плюсы**:
- Легко обойти NAT или фаерволл — данные сами прилетают к тебе.
- Гибкость: каждый агент сам решает, что отправить и когда.
**Минусы**:
- Сложно контролировать: все шлют данные, сервер может упасть при большой нагрузке.
- Неправильная настройка может привести к бардаку и падению сервиса.

## 6.
- **Prometheus**: Pull
- **TICK (Telegraf, InfluxDB, Chronograf, Kapacitor)**: Push.
- **Zabbix**: Гибрид.
- **VictoriaMetrics**: Гибрид.
- **Nagios**: Pull

## 7.
ChronografWEB

![ChronografWEB](https://github.com/GrizzlikovOleg/Netology/blob/main/tasks_monitoring/mo_1/ChronografWEB.png)

## 8.
CPU_USAGE

![ChronografWEB_1](https://github.com/GrizzlikovOleg/Netology/blob/main/tasks_monitoring/mo_1/ChronografWEB_1.png)

## 9.
Docker Measurment

![ChronografWEB_2](https://github.com/GrizzlikovOleg/Netology/blob/main/tasks_monitoring/mo_1/ChronografWEB_2.png)